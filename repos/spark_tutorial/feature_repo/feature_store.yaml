project: spark_tutorial
# By default, the registry is a file (but can be turned into a more scalable SQL-backed registry)
# On GCP/AWS, minimally you should create a GCS/S3 bucket for a remote file registry
registry: data/registry.db
provider: local
offline_store:
  type: spark
  spark_conf:
    spark.master: "local[*]"
    spark.ui.enabled: "false"
    spark.eventLog.enabled: "false"
    spark.sql.catalogImplementation: "hive"
    spark.sql.parser.quotedRegexColumnNames: "true"
    spark.sql.session.timeZone: "UTC"
    spark.sql.execution.arrow.fallback.enabled: "true"
    spark.sql.execution.arrow.pyspark.enabled: "true"
    spark.sql.legacy.parquet.nanosAsLong: "true"

    "spark.sql.parquet.timestampType": "TIMESTAMP_MICROS"
    "spark.sql.parquet.int96AsTimestamp": "true"
    "spark.sql.parquet.datetimeRebaseModeInRead": "CORRECTED"
online_store:
  path: data/online_store.db
entity_key_serialization_version: 2
